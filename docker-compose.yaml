---
version: '3.7'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    hostname: zookeeper
    container_name: zookeeper
    command: zookeeper-server-start /etc/kafka/zookeeper.properties
    environment:
      EXTRA_ARGS: -javaagent:/usr/share/jmx-exporter/jmx_prometheus_javaagent-0.18.0.jar=9103:/usr/share/jmx-exporter/zookeeper.yml
    volumes:
    - ./zookeeper:/etc/kafka
    - ./jmx-exporter:/usr/share/jmx-exporter
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 512M

  kafka1:
    image: confluentinc/cp-server:7.4.0
    hostname: kafka1
    container_name: kafka1
    depends_on:
      - zookeeper
    command: kafka-server-start /etc/kafka/server.properties
    environment:
      EXTRA_ARGS: -javaagent:/usr/share/jmx-exporter/jmx_prometheus_javaagent-0.18.0.jar=9101:/usr/share/jmx-exporter/kafka_broker.yml
    volumes:
    - ./kafka1:/etc/kafka
    - ./jmx-exporter:/usr/share/jmx-exporter
    deploy:
      resources:
        limits:
          cpus: "1.5"
          memory: 1536M

  kafka2:
    image: confluentinc/cp-server:7.4.0
    hostname: kafka2
    container_name: kafka2
    depends_on:
      - zookeeper
    command: kafka-server-start /etc/kafka/server.properties
    environment:
      EXTRA_ARGS: -javaagent:/usr/share/jmx-exporter/jmx_prometheus_javaagent-0.18.0.jar=9102:/usr/share/jmx-exporter/kafka_broker.yml
    volumes:
    - ./kafka2:/etc/kafka
    - ./jmx-exporter:/usr/share/jmx-exporter
    deploy:
      resources:
        limits:
          cpus: "1.5"
          memory: 1536M
  
  kafka3:
    image: confluentinc/cp-server:7.4.0
    hostname: kafka3
    container_name: kafka3
    depends_on:
      - zookeeper
    command: kafka-server-start /etc/kafka/server.properties
    environment:
      EXTRA_ARGS: -javaagent:/usr/share/jmx-exporter/jmx_prometheus_javaagent-0.18.0.jar=9103:/usr/share/jmx-exporter/kafka_broker.yml
    volumes:
    - ./kafka3:/etc/kafka
    - ./jmx-exporter:/usr/share/jmx-exporter
    deploy:
      resources:
        limits:
          cpus: "1.5"
          memory: 1536M

  schema-registry:
    image: confluentinc/cp-schema-registry:7.4.0
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    command: schema-registry-start /etc/schema-registry/schema-registry.properties
    ports:
      - "8081:8081"
    volumes:
    - ./schema-registry:/etc/schema-registry
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 512M

  control-center:
    image: confluentinc/cp-enterprise-control-center:7.4.0
    hostname: control-center
    container_name: control-center
    depends_on:
      - kafka1
      - kafka2
      - kafka3
      - schema-registry
    ports:
      - "9021:9021"
    command: control-center-start /etc/confluent-control-center/control-center-production.properties
    environment:
      PORT: 9021
    volumes:
    - ./confluent-control-center:/etc/confluent-control-center
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 1024M

  kfkclient:
    build: ./client
    hostname: kfkclient
    container_name: kfkclient
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    volumes:
    - ./client:/opt/client
    deploy:
      resources:
        limits:
          cpus: "0.1"
          memory: 256M

  init:
    build: ./client
    hostname: init
    container_name: init
    entrypoint: /opt/scripts/command.sh /opt/scripts/kafka.sh
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    restart: on-failure
    volumes:
    - ./scripts/start.sh:/opt/scripts/kafka.sh
    - ./scripts/client.sh:/opt/scripts/command.sh
    deploy:
      resources:
        limits:
          cpus: "0.1"
          memory: 256M

  producer1:
    image: confluentinc/cp-server:7.4.0
    hostname: producer1
    container_name: producer1
    entrypoint: /opt/scripts/kafka.sh
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    command: kafka-producer-perf-test \
              --topic app_telemetry \
              --num-records 99999999999 \
              --throughput -1 \
              --record-size 10000 \
              --producer.config  /opt/client/client.properties
    volumes:
    - ./producer/client.properties:/opt/client/client.properties
    - ./scripts/setup.sh:/opt/scripts/kafka.sh
    - ./scripts/client.sh:/opt/scripts/command.sh
    deploy:
      resources:
        limits:
          cpus: "0.1"
          memory: 256M

  producer2:
    image: confluentinc/cp-server:7.4.0
    hostname: producer2
    container_name: producer2
    entrypoint: /opt/scripts/kafka.sh
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    command: kafka-producer-perf-test \
              --topic debit_transactions \
              --num-records 99999999999 \
              --throughput -1 \
              --record-size 10000 \
              --producer.config  /opt/client/client.properties
    volumes:
    - ./producer/client.properties:/opt/client/client.properties
    - ./scripts/setup.sh:/opt/scripts/kafka.sh
    - ./scripts/client.sh:/opt/scripts/command.sh
    deploy:
      resources:
        limits:
          cpus: "0.1"
          memory: 256M
  
  producer3:
    image: confluentinc/cp-server:7.4.0
    hostname: producer3
    container_name: producer3
    entrypoint: /opt/scripts/kafka.sh
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    command: kafka-producer-perf-test \
              --topic credit_transactions \
              --num-records 99999999999 \
              --throughput -1 \
              --record-size 10000 \
              --producer.config  /opt/client/client.properties
    volumes:
    - ./producer/client.properties:/opt/client/client.properties
    - ./scripts/setup.sh:/opt/scripts/kafka.sh
    - ./scripts/client.sh:/opt/scripts/command.sh
    deploy:
      resources:
        limits:
          cpus: "0.1"
          memory: 256M

  producer4:
    image: confluentinc/cp-server:7.4.0
    hostname: producer4
    container_name: producer4
    entrypoint: /opt/scripts/kafka.sh
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    command: kafka-producer-perf-test \
              --topic loan_payments \
              --num-records 99999999999 \
              --throughput -1 \
              --record-size 10000 \
              --producer.config  /opt/client/client.properties
    volumes:
    - ./producer/client.properties:/opt/client/client.properties
    - ./scripts/setup.sh:/opt/scripts/kafka.sh
    - ./scripts/client.sh:/opt/scripts/command.sh
    deploy:
      resources:
        limits:
          cpus: "0.1"
          memory: 256M

  producer5:
    image: confluentinc/cp-server:7.4.0
    hostname: producer5
    container_name: producer5
    entrypoint: /opt/scripts/kafka.sh
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    command: kafka-producer-perf-test \
              --topic new_accounts \
              --num-records 99999999999 \
              --throughput -1 \
              --record-size 10000 \
              --producer.config  /opt/client/client.properties
    volumes:
    - ./producer/client.properties:/opt/client/client.properties
    - ./scripts/setup.sh:/opt/scripts/kafka.sh
    - ./scripts/client.sh:/opt/scripts/command.sh
    deploy:
      resources:
        limits:
          cpus: "0.1"
          memory: 256M

  producer6:
    image: confluentinc/cp-server:7.4.0
    hostname: producer6
    container_name: producer6
    entrypoint: /opt/scripts/kafka.sh
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    command: kafka-producer-perf-test \
              --topic business_requests \
              --num-records 99999999999 \
              --throughput -1 \
              --record-size 10000 \
              --producer.config  /opt/client/client.properties
    volumes:
    - ./producer/client.properties:/opt/client/client.properties
    - ./scripts/setup.sh:/opt/scripts/kafka.sh
    - ./scripts/client.sh:/opt/scripts/command.sh
    deploy:
      resources:
        limits:
          cpus: "0.1"
          memory: 256M

  producer7:
    image: confluentinc/cp-server:7.4.0
    hostname: producer7
    container_name: producer7
    entrypoint: /opt/scripts/kafka.sh
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    command: kafka-producer-perf-test \
              --topic international_transactions \
              --num-records 99999999999 \
              --throughput -1 \
              --record-size 10000 \
              --producer.config  /opt/client/client.properties
    volumes:
    - ./producer/client.properties:/opt/client/client.properties
    - ./scripts/setup.sh:/opt/scripts/kafka.sh
    - ./scripts/client.sh:/opt/scripts/command.sh
    deploy:
      resources:
        limits:
          cpus: "0.1"
          memory: 256M

  producer8:
    image: confluentinc/cp-server:7.4.0
    hostname: producer8
    container_name: producer8
    entrypoint: /opt/scripts/kafka.sh
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    command: kafka-producer-perf-test \
              --topic account_audit \
              --num-records 99999999999 \
              --throughput -1 \
              --record-size 10000 \
              --producer.config  /opt/client/client.properties
    volumes:
    - ./producer/client.properties:/opt/client/client.properties
    - ./scripts/setup.sh:/opt/scripts/kafka.sh
    - ./scripts/client.sh:/opt/scripts/command.sh
    deploy:
      resources:
        limits:
          cpus: "0.1"
          memory: 256M

  producer9:
    image: confluentinc/cp-server:7.4.0
    hostname: producer9
    container_name: producer9
    entrypoint: /opt/scripts/kafka.sh
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    command: kafka-producer-perf-test \
              --topic fraud_detection \
              --num-records 99999999999 \
              --throughput -1 \
              --record-size 10000 \
              --producer.config  /opt/client/client.properties
    volumes:
    - ./producer/client.properties:/opt/client/client.properties
    - ./scripts/setup.sh:/opt/scripts/kafka.sh
    - ./scripts/client.sh:/opt/scripts/command.sh
    deploy:
      resources:
        limits:
          cpus: "0.1"
          memory: 256M

  consumer:
    build: ./consumer
    hostname: consumer
    container_name: consumer
    entrypoint: /opt/scripts/kafka.sh
    depends_on:
      - producer1
    command: java -jar  app.jar /opt/client/client.properties
    volumes:
    - ./consumer/client.properties:/opt/client/client.properties
    - ./scripts/setup.sh:/opt/scripts/kafka.sh
    - ./scripts/client.sh:/opt/scripts/command.sh
    deploy:
      resources:
        limits:
          cpus: "0.1"
          memory: 256M

  openldap:
    image: osixia/openldap:1.3.0
    hostname: openldap
    container_name: openldap
    environment:
        LDAP_ORGANISATION: "ConfluentDemo"
        LDAP_DOMAIN: "confluentdemo.io"
        LDAP_BASE_DN: "dc=confluentdemo,dc=io"
    ports:
      - "389:389"
    volumes:
        - ./ldap/ldap_users:/container/service/slapd/assets/config/bootstrap/ldif/custom
    command: "--copy-service --loglevel debug"
    deploy:
      resources:
        limits:
          cpus: "0.1"
          memory: 256M

  prometheus:
    image: prom/prometheus:v2.37.7
    container_name: prometheus
    volumes:
      - ./prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    restart: unless-stopped
    ports:
    - 9090:9090
    expose:
    - 9090
    deploy:
      resources:
        limits:
          cpus: "0.2"
          memory: 256M

  grafana:
    image: grafana/grafana:8.5.24
    container_name: grafana
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    environment:
      - GF_SECURITY_ADMIN_USER=${ADMIN_USER}
      - GF_SECURITY_ADMIN_PASSWORD=${ADMIN_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
    restart: unless-stopped
    ports:
    - 3000:3000
    expose:
      - 3000
    deploy:
      resources:
        limits:
          cpus: "0.2"
          memory: 256M

volumes:
    prometheus_data: {}
    grafana_data: {}

